Using gpu device 1: Tesla K80 (CNMeM is disabled, cuDNN 5005)
  0%| | 0/301 [00:00<?, ?it/s]  0%| | 1/301 [41:04<205:23:21, 2464.67s/it]  1%| | 2/301 [1:22:06<204:37:22, 2463.69s/it]  1%| | 3/301 [2:03:01<203:43:19, 2461.07s/it]  1%| | 4/301 [2:43:54<202:51:41, 2458.93s/it]  2%| | 5/301 [3:24:46<201:59:19, 2456.62s/it]  2%| | 6/301 [4:05:41<201:15:43, 2456.08s/it]  2%| | 7/301 [4:46:31<200:26:37, 2454.41s/it]  3%| | 8/301 [5:27:19<199:36:48, 2452.59s/it]  3%| | 9/301 [6:08:09<198:51:29, 2451.68s/it]  3%| | 10/301 [6:49:01<198:11:50, 2451.93s/it]  4%| | 11/301 [7:29:52<197:28:37, 2451.44s/it]  4%| | 12/301 [8:10:42<196:46:40, 2451.21s/it]  4%| | 13/301 [8:51:33<196:05:04, 2451.06s/it]  5%| | 14/301 [9:32:21<195:19:57, 2450.17s/it]  5%| | 15/301 [10:13:09<194:35:53, 2449.49s/it]  5%| | 16/301 [10:54:01<193:58:21, 2450.18s/it]  6%| | 17/301 [11:34:51<193:17:42, 2450.22s/it]  6%| | 18/301 [12:15:39<192:33:12, 2449.44s/it]  6%| | 19/301 [12:56:30<191:55:25, 2450.09s/it]  7%| | 20/301 [13:37:23<191:18:15, 2450.87s/it]  7%| | 21/301 [14:18:26<190:53:59, 2454.43s/it]  7%| | 22/301 [14:59:17<190:08:42, 2453.49s/it]  8%| | 23/301 [15:40:08<189:24:13, 2452.71s/it]  8%| | 24/301 [16:21:00<188:41:58, 2452.41s/it]  8%| | 25/301 [17:01:51<187:59:31, 2452.07s/it]  9%| | 26/301 [17:42:41<187:15:14, 2451.32s/it]  9%| | 27/301 [18:23:32<186:34:31, 2451.36s/it]  9%| | 28/301 [19:05:05<186:50:40, 2463.89s/it] 10%| | 29/301 [19:46:45<186:59:06, 2474.80s/it] 10%| | 30/301 [20:28:26<186:52:48, 2482.54s/it] 10%|1| 31/301 [21:10:05<186:33:00, 2487.34s/it]Loading training data...
Loading validation data...
/home/faiz/Desktop/datasets/processed-data/images320x240/COCO_val2014_000000065948.png

/home/faiz/Desktop/datasets/processed-data/saliency320x240/COCO_val2014_000000065948.png

Input: (3, 240, 320)
conv1_1: (64, 240, 320)
conv1_2: (64, 240, 320)
pool1: (64, 120, 160)
conv2_1: (128, 120, 160)
conv2_2: (128, 120, 160)
pool2: (128, 60, 80)
conv3_1: (256, 60, 80)
conv3_2: (256, 60, 80)
conv3_3: (256, 60, 80)
pool3: (256, 30, 40)
conv4_1: (512, 30, 40)
conv4_2: (512, 30, 40)
conv4_3: (512, 30, 40)
pool4: (512, 15, 20)
conv5_1: (512, 15, 20)
conv5_2: (512, 15, 20)
conv5_3: (512, 15, 20)
uconv5_3: (512, 15, 20)
uconv5_2: (512, 15, 20)
uconv5_1: (512, 15, 20)
upool4: (512, 30, 40)
uconv4_3: (512, 30, 40)
uconv4_2: (512, 30, 40)
uconv4_1: (512, 30, 40)
upool3: (512, 60, 80)
uconv3_3: (256, 60, 80)
uconv3_2: (256, 60, 80)
uconv3_1: (256, 60, 80)
upool2: (256, 120, 160)
uconv2_2: (128, 120, 160)
uconv2_1: (128, 120, 160)
upool1: (128, 240, 320)
uconv1_2: (64, 240, 320)
uconv1_1: (64, 240, 320)
output: (1, 240, 320)
Input: (4, 240, 320)
merge: (3, 240, 320)
conv1: (32, 240, 320)
pool1: (32, 60, 80)
conv2_1: (64, 60, 80)
conv2_2: (64, 60, 80)
pool2: (64, 30, 40)
conv3_1: (64, 30, 40)
conv3_2: (64, 30, 40)
pool3: (64, 15, 20)
fc4: (100,)
fc5: (2,)
prob: (1,)
Epoch: 0  train_loss-> (0.70191692178830123, 0.6931695034488653, 0.1901627046844134)
Epoch: 1  train_loss-> (0.70051134205781496, 0.69315306937847387, 0.14816928019699377)
Epoch: 2  train_loss-> (0.70021666796543658, 0.69315038907986426, 0.14201753849211413)
Epoch: 3  train_loss-> (0.69997328156844163, 0.693149249905195, 0.13819559682638216)
Epoch: 4  train_loss-> (0.69988158822823798, 0.69314873848970115, 0.13587201224305692)
Epoch: 5  train_loss-> (0.69982486122693766, 0.69314841983410025, 0.13447731996002871)
Epoch: 6  train_loss-> (0.69979574836981606, 0.69314819784500659, 0.13360255443228361)
Epoch: 7  train_loss-> (0.6997349017705673, 0.69314806163311005, 0.13264169555921584)
Epoch: 8  train_loss-> (0.699700249120211, 0.69314793611948311, 0.1316366545521678)
Epoch: 9  train_loss-> (0.69968292537407994, 0.69314783773361111, 0.1311330467175979)
Epoch: 10  train_loss-> (0.6996651687301122, 0.69314776647549414, 0.13070668986974618)
Epoch: 11  train_loss-> (0.69965680784139883, 0.69314770400524139, 0.13032732540980363)
Epoch: 12  train_loss-> (0.69961467499916374, 0.69314765567198777, 0.12983966998469371)
Epoch: 13  train_loss-> (0.6996213134664756, 0.69314761555347693, 0.1295860463466782)
Epoch: 14  train_loss-> (0.69959768423667323, 0.69314758575115454, 0.12918072346693429)
Epoch: 15  train_loss-> (0.69960098446179664, 0.69314755499362946, 0.12909764373818269)
Epoch: 16  train_loss-> (0.69957164082771695, 0.69314752882107711, 0.12874511466958585)
Epoch: 17  train_loss-> (0.69954534677358771, 0.69314750054707897, 0.12847802475190315)
Epoch: 18  train_loss-> (0.69954373362736821, 0.69314748239822876, 0.12819299254661951)
Epoch: 19  train_loss-> (0.69953579474718142, 0.69314745909128439, 0.12802031244605017)
Epoch: 20  train_loss-> (0.69953458889936793, 0.69314743693058312, 0.12789724413783121)
Epoch: 21  train_loss-> (0.69951770874934316, 0.69314742814271879, 0.12758830053588519)
Epoch: 22  train_loss-> (0.69952259212732315, 0.69314741515196288, 0.12759672513661477)
Epoch: 23  train_loss-> (0.69950363823236561, 0.69314739929559899, 0.12735164490265724)
Epoch: 24  train_loss-> (0.69948746111148441, 0.69314738783316732, 0.12699288194282696)
Epoch: 25  train_loss-> (0.69948576314327049, 0.69314737274096561, 0.12696052722346324)
Epoch: 26  train_loss-> (0.69948719327266395, 0.69314736318893921, 0.12677022616546124)
Epoch: 27  train_loss-> (0.69947479741695595, 0.69314735707564235, 0.12650827879611498)
Epoch: 28  train_loss-> (0.69947635191373336, 0.69314734637737274, 0.12659908869327643)
Epoch: 29  train_loss-> (0.69946267933417594, 0.69314734141031897, 0.12638506111808312)
Epoch: 30  train_loss-> (0.69945906159969473, 0.69314733166725206, 0.12616678613882798)
Epoch: 31  train_loss-> (0.69945525263364494, 0.69314732498083365, 0.126 11%|1| 32/301 [21:51:43<186:07:05, 2490.80s/it] 11%|1| 33/301 [22:32:56<185:01:26, 2485.40s/it] 11%|1| 34/301 [23:13:51<183:39:12, 2476.23s/it] 12%|1| 35/301 [23:54:42<182:24:51, 2468.76s/it] 12%|1| 36/301 [24:35:34<181:21:24, 2463.72s/it] 12%|1| 37/301 [25:16:27<180:26:22, 2460.54s/it] 13%|1| 38/301 [25:57:22<179:36:46, 2458.58s/it] 13%|1| 39/301 [26:38:13<178:46:40, 2456.49s/it] 13%|1| 40/301 [27:19:07<178:02:45, 2455.81s/it] 14%|1| 41/301 [27:59:57<177:14:14, 2454.05s/it] 14%|1| 42/301 [28:40:48<176:28:31, 2452.94s/it] 14%|1| 43/301 [29:21:42<175:49:15, 2453.32s/it] 15%|1| 44/301 [30:02:32<175:04:40, 2452.45s/it] 15%|1| 45/301 [30:43:25<174:24:41, 2452.66s/it] 15%|1| 46/301 [31:24:20<173:46:37, 2453.33s/it] 16%|1| 47/301 [32:05:13<173:04:57, 2453.14s/it] 16%|1| 48/301 [32:46:03<172:19:53, 2452.15s/it] 16%|1| 49/301 [33:27:01<171:47:05, 2454.07s/it] 17%|1| 50/301 [34:07:55<171:05:20, 2453.87s/it] 17%|1| 51/301 [34:48:47<170:22:43, 2453.45s/it] 17%|1| 52/301 [35:29:41<169:42:46, 2453.68s/it] 18%|1| 53/301 [36:10:35<169:02:07, 2453.74s/it] 18%|1| 54/301 [36:51:26<168:17:46, 2452.90s/it] 18%|1| 55/301 [37:32:24<167:42:21, 2454.23s/it] 19%|1| 56/301 [38:13:17<167:00:12, 2453.93s/it] 19%|1| 57/301 [38:54:08<166:15:58, 2453.11s/it] 19%|1| 58/301 [39:35:32<166:12:55, 2462.45s/it] 20%|1| 59/301 [40:17:13<166:18:16, 2473.95s/it] 20%|1| 60/301 [40:58:52<166:06:37, 2481.32s/it] 20%|2| 61/301 [41:40:26<165:40:36, 2485.15s/it] 21%|2| 62/301 [42:22:01<165:10:54, 2488.10s/it] 21%|2| 63/301 [43:03:00<163:55:40, 2479.58s/it] 21%|2| 64/301 [43:44:07<162:59:01, 2475.70s/it] 22%|2| 65/301 [44:25:06<161:58:35, 2470.83s/it] 22%|2| 66/301 [45:06:41<161:45:41, 2478.05s/it] 22%|2| 67/301 [45:47:46<160:48:18, 2473.93s/it] 23%|2| 68/301 [46:29:11<160:19:48, 2477.21s/it] 23%|2| 69/301 [47:10:54<160:09:08, 2485.12s/it] 23%|2| 70/301 [47:52:11<159:18:08, 2482.63s/it] 24%|2| 71/301 [48:33:15<158:14:54, 2476.93s/it] 24%|2| 72/301 [49:14:17<157:16:55, 2472.56s/it] 24%|2| 73/301 [49:55:23<156:28:18, 2470.61s/it] 25%|2| 74/301 [50:36:25<155:37:17, 2468.01s/it] 25%|2| 75/301 [51:17:29<154:52:01, 2466.91s/it] 25%|2| 76/301 [51:58:35<154:09:04, 2466.42s/it] 26%|2| 77/301 [52:39:37<153:23:06, 2465.12s/it] 26%|2| 78/301 [53:20:39<152:38:50, 2464.26s/it]07393721834972)
Epoch: 32  train_loss-> (0.69943910798965359, 0.69314731944065833, 0.12599664575491959)
Epoch: 33  train_loss-> (0.69942877097771716, 0.69314731466464508, 0.12583326268941164)
Epoch: 34  train_loss-> (0.69943495304920733, 0.69314730568574023, 0.1257573920660294)
Epoch: 35  train_loss-> (0.69942220816245448, 0.69314730243805123, 0.12561600492932859)
Epoch: 36  train_loss-> (0.69941172806116247, 0.69314729823515964, 0.12541048257396772)
Epoch: 37  train_loss-> (0.6994086857407521, 0.69314729403226805, 0.12527865391129103)
Epoch: 38  train_loss-> (0.69940911691922403, 0.69314728849209273, 0.12531190938674486)
Epoch: 39  train_loss-> (0.6993932141325413, 0.69314728619960642, 0.12512241139148289)
Epoch: 40  train_loss-> (0.69939652601113689, 0.69314728218775534, 0.12499448425399187)
Epoch: 41  train_loss-> (0.69939430860372687, 0.69314727779382312, 0.12491543003572868)
Epoch: 42  train_loss-> (0.69939105098064125, 0.69314727550133681, 0.12489531210695322)
Epoch: 43  train_loss-> (0.69937920646789742, 0.69314727301780998, 0.12467543448870763)
Epoch: 44  train_loss-> (0.69937272293445396, 0.69314727206260729, 0.12461346829644381)
Epoch: 45  train_loss-> (0.69935442067873788, 0.69314726193745935, 0.12446565551157945)
Epoch: 46  train_loss-> (0.69937381778772056, 0.69314726308370245, 0.12454374024692254)
Epoch: 47  train_loss-> (0.69934981602888846, 0.69314725639728403, 0.1242887448423948)
Epoch: 48  train_loss-> (0.69935453071808207, 0.69314725792560827, 0.12418599983151907)
Epoch: 49  train_loss-> (0.69935814482279313, 0.69314725582416237, 0.12413002944623049)
Epoch: 50  train_loss-> (0.69933773195132232, 0.69314725334063554, 0.12406102548807095)
Epoch: 51  train_loss-> (0.69933947481406045, 0.69314724780046022, 0.12393748786491461)
Epoch: 52  train_loss-> (0.69934280541462779, 0.69314724722733867, 0.1239665494992947)
Epoch: 53  train_loss-> (0.69934133879649329, 0.69314724569901442, 0.12384311147989371)
Epoch: 54  train_loss-> (0.69932083690013636, 0.69314724397964966, 0.12364696345936793)
Epoch: 55  train_loss-> (0.69932945798604917, 0.6931472443617307, 0.12371591275605635)
Epoch: 56  train_loss-> (0.69932614324184561, 0.69314723805739331, 0.1236205891204568)
Epoch: 57  train_loss-> (0.69932460727599954, 0.69314723500074482, 0.12354060240949576)
Epoch: 58  train_loss-> (0.69931121418873465, 0.69314723366346109, 0.12341172787814568)
Epoch: 59  train_loss-> (0.69930809239546454, 0.69314723614698803, 0.12331711488943069)
Epoch: 60  train_loss-> (0.69931571357525313, 0.69314723251721799, 0.1233239067861667)
Epoch: 61  train_loss-> (0.69929539794341111, 0.6931472304157722, 0.12318000295318854)
Epoch: 62  train_loss-> (0.69929874688386917, 0.69314723060681271, 0.12304133917085636)
Epoch: 63  train_loss-> (0.69929302541109228, 0.69314722659496164, 0.1229818409595352)
Epoch: 64  train_loss-> (0.69929759987653828, 0.69314722659496164, 0.12300797067105006)
Epoch: 65  train_loss-> (0.69929292110296393, 0.69314722850536692, 0.12293694686526671)
Epoch: 66  train_loss-> (0.69929098700865722, 0.69314722258311057, 0.1228047947709759)
Epoch: 67  train_loss-> (0.69927585201385689, 0.69314722659496164, 0.12267190366028211)
Epoch: 68  train_loss-> (0.69928504526615143, 0.6931472241114347, 0.12260745389339252)
Epoch: 69  train_loss-> (0.69927002623295176, 0.69314722258311057, 0.12251663112487549)
Epoch: 70  train_loss-> (0.69927081083640075, 0.69314721990854311, 0.12251299796387172)
Epoch: 71  train_loss-> (0.69925915029568553, 0.69314721780709732, 0.12230431651457763)
Epoch: 72  train_loss-> (0.69925469446640753, 0.69314721398628676, 0.12226892071656692)
Epoch: 73  train_loss-> (0.69926046255307317, 0.69314721532357049, 0.12234472547872709)
Epoch: 74  train_loss-> (0.69925419432230485, 0.693147215514611, 0.12219577925040936)
Epoch: 75  train_loss-> (0.69924942862529016, 0.69314721417732728, 0.12216930344509773)
Epoch: 76  train_loss-> (0.69925806021843206, 0.69314721112067879, 0.12212213042836922)
Epoch: 77  train_loss-> (0.69924804530082607, 0.69314721035651672, 0.12208864002082592)
Epoch: 78  train_loss-> (0.69924312963699686,  26%|2| 79/301 [54:01:42<151:56:51, 2464.02s/it] 27%|2| 80/301 [54:42:46<151:15:19, 2463.89s/it] 27%|2| 81/301 [55:23:51<150:35:45, 2464.30s/it] 27%|2| 82/301 [56:04:58<149:57:30, 2465.07s/it] 28%|2| 83/301 [56:46:05<149:18:46, 2465.72s/it] 28%|2| 84/301 [57:27:10<148:36:38, 2465.43s/it] 28%|2| 85/301 [58:08:20<148:00:27, 2466.80s/it] 29%|2| 86/301 [58:49:29<147:22:11, 2467.59s/it] 29%|2| 87/301 [59:30:38<146:41:52, 2467.82s/it] 29%|2| 88/301 [60:11:44<145:59:07, 2467.36s/it] 30%|2| 89/301 [60:52:49<145:15:16, 2466.59s/it] 30%|2| 90/301 [61:33:54<144:32:55, 2466.24s/it] 30%|3| 91/301 [62:15:01<143:52:26, 2466.41s/it] 31%|3| 92/301 [62:56:07<143:11:00, 2466.32s/it] 31%|3| 93/301 [63:37:13<142:28:57, 2466.04s/it] 31%|3| 94/301 [64:18:22<141:50:51, 2466.92s/it] 32%|3| 95/301 [64:59:28<141:09:25, 2466.82s/it] 32%|3| 96/301 [65:40:32<140:25:11, 2465.91s/it] 32%|3| 97/301 [66:21:36<139:41:48, 2465.24s/it] 33%|3| 98/301 [67:02:38<138:58:14, 2464.50s/it] 33%|3| 99/301 [67:43:43<138:17:01, 2464.46s/it] 33%|3| 100/301 [68:24:48<137:36:32, 2464.64s/it] 34%|3| 101/301 [69:05:54<136:56:50, 2465.05s/it] 34%|3| 102/301 [69:47:00<136:16:24, 2465.25s/it] 34%|3| 103/301 [70:28:03<135:33:34, 2464.72s/it] 35%|3| 104/301 [71:09:06<134:51:12, 2464.33s/it] 35%|3| 105/301 [71:50:10<134:09:15, 2464.06s/it] 35%|3| 106/301 [72:31:16<133:30:07, 2464.65s/it] 36%|3| 107/301 [73:12:18<132:46:52, 2463.98s/it] 36%|3| 108/301 [73:53:21<132:04:34, 2463.60s/it] 36%|3| 109/301 [74:34:27<131:26:01, 2464.39s/it] 37%|3| 110/301 [75:15:29<130:42:02, 2463.47s/it] 37%|3| 111/301 [75:56:32<130:00:50, 2463.43s/it] 37%|3| 112/301 [76:37:38<129:22:31, 2464.29s/it] 38%|3| 113/301 [77:18:46<128:44:17, 2465.20s/it] 38%|3| 114/301 [77:59:50<128:02:13, 2464.89s/it] 38%|3| 115/301 [78:40:56<127:22:05, 2465.19s/it] 39%|3| 116/301 [79:21:59<126:39:42, 2464.77s/it] 39%|3| 117/301 [80:03:04<125:58:47, 2464.83s/it] 39%|3| 118/301 [80:44:09<125:17:55, 2464.90s/it] 40%|3| 119/301 [81:25:14<124:36:30, 2464.78s/it] 40%|3| 120/301 [82:06:20<123:56:34, 2465.16s/it] 40%|4| 121/301 [82:47:27<123:17:29, 2465.83s/it] 41%|4| 122/301 [83:28:33<122:35:45, 2465.62s/it] 41%|4| 123/301 [84:09:38<121:54:53, 2465.70s/it] 41%|4| 124/301 [84:50:42<121:11:39, 2464.97s/it]0.69314720863715196, 0.12198489565306748)
Epoch: 79  train_loss-> (0.69923410583765078, 0.6931472069177872, 0.12188113862887406)
Epoch: 80  train_loss-> (0.69923696055626261, 0.69314720577154409, 0.12186284501774189)
Epoch: 81  train_loss-> (0.69923785443489372, 0.69314720710882771, 0.12167125644210057)
Epoch: 82  train_loss-> (0.69923670780964386, 0.69314720347905767, 0.12181713167004861)
Epoch: 83  train_loss-> (0.6992264602046746, 0.69314720863715196, 0.12165509902227384)
Epoch: 84  train_loss-> (0.69921815739228177, 0.69314720118657136, 0.12147623357864526)
Epoch: 85  train_loss-> (0.69922266805019129, 0.69314720156865239, 0.12137616826937749)
Epoch: 86  train_loss-> (0.69921713666273999, 0.69314720309697664, 0.12144553740150653)
Epoch: 87  train_loss-> (0.69921093797072387, 0.69314720405217933, 0.12127498589838162)
Epoch: 88  train_loss-> (0.69922248465128434, 0.69314720004032815, 0.12137573964607257)
Epoch: 89  train_loss-> (0.69920561252496183, 0.69314720042240929, 0.1211325421403998)
Epoch: 90  train_loss-> (0.69920844546495342, 0.69314719851200401, 0.12110053169994782)
Epoch: 91  train_loss-> (0.69921172047272706, 0.6931471983209635, 0.12121256875495116)
Epoch: 92  train_loss-> (0.6991905480241164, 0.69314719507327449, 0.12093616914577208)
Epoch: 93  train_loss-> (0.69918245268173707, 0.69314719450015283, 0.12087225333715861)
Epoch: 94  train_loss-> (0.69919522756185282, 0.69314719717472029, 0.12096290760792983)
Epoch: 95  train_loss-> (0.69919167000513816, 0.69314719373599076, 0.1209013450365418)
Epoch: 96  train_loss-> (0.69919104625781381, 0.69314719316286921, 0.12081059125753549)
Epoch: 97  train_loss-> (0.69918114577348411, 0.6931471929718287, 0.12065436810446091)
Epoch: 98  train_loss-> (0.69917257607747352, 0.69314719755680132, 0.12053859424896729)
Epoch: 99  train_loss-> (0.69917150739675915, 0.69314719526431501, 0.12053126868051596)
Epoch: 100  train_loss-> (0.69916784514983499, 0.69314719278078818, 0.12042559365718028)
Epoch: 101  train_loss-> (0.69917197429980982, 0.69314719316286921, 0.12044188081740569)
Epoch: 102  train_loss-> (0.69916657243783653, 0.69314718972413969, 0.12035746979885377)
Epoch: 103  train_loss-> (0.69917178860841656, 0.69314718704957223, 0.12044709827750921)
Epoch: 104  train_loss-> (0.69915070747717833, 0.69314719106142342, 0.12020566720419969)
Epoch: 105  train_loss-> (0.69916645953288448, 0.69314719278078818, 0.12033180395762126)
Epoch: 106  train_loss-> (0.69915224134157861, 0.69314718724061286, 0.12010886061650056)
Epoch: 107  train_loss-> (0.69914243695063472, 0.69314718533020758, 0.11996546989450088)
Epoch: 108  train_loss-> (0.69915021325533211, 0.69314718895997751, 0.12011201789554878)
Epoch: 109  train_loss-> (0.69913126757511723, 0.69314718609436965, 0.11979270907930839)
Epoch: 110  train_loss-> (0.69914048337019408, 0.69314718838685596, 0.11987572134687351)
Epoch: 111  train_loss-> (0.69914592344027304, 0.69314718934205866, 0.11984871757718232)
Epoch: 112  train_loss-> (0.69912200707655692, 0.69314718704957223, 0.1195756501924151)
Epoch: 113  train_loss-> (0.69912990660239493, 0.69314718571228862, 0.11955572999058625)
Epoch: 114  train_loss-> (0.69911879167342794, 0.69314718437500489, 0.11953247594050108)
Epoch: 115  train_loss-> (0.6991238200511688, 0.69314718609436965, 0.11951520535139701)
Epoch: 116  train_loss-> (0.69912251639060485, 0.69314718685853172, 0.11947983663338117)
Epoch: 117  train_loss-> (0.69912542631992924, 0.6931471845660454, 0.11953906060602421)
Epoch: 118  train_loss-> (0.69910868505636847, 0.69314718533020758, 0.11923575293845855)
Epoch: 119  train_loss-> (0.69911747330274332, 0.69314718303772116, 0.11939480535399455)
Epoch: 120  train_loss-> (0.69910958065436435, 0.69314717864378905, 0.11919551158849245)
Epoch: 121  train_loss-> (0.69910638664777458, 0.69314718093627536, 0.11907534752614223)
Epoch: 122  train_loss-> (0.69909906540161526, 0.69314717998107278, 0.11901846095824088)
Epoch: 123  train_loss-> (0.69909885258246696, 0.69314718112731588, 0.1190144188511066)
Epoch: 124  train_loss-> (0.69909145854986632, 0.69314718265564013, 0.11899203052 42%|4| 125/301 [85:31:44<120:28:39, 2464.31s/it] 42%|4| 126/301 [86:12:49<119:47:40, 2464.35s/it] 42%|4| 127/301 [86:53:55<119:07:44, 2464.74s/it] 43%|4| 128/301 [87:34:56<118:23:57, 2463.80s/it] 43%|4| 129/301 [88:15:56<117:39:26, 2462.60s/it] 43%|4| 130/301 [88:57:01<117:00:39, 2463.39s/it] 44%|4| 131/301 [89:38:05<116:19:51, 2463.48s/it] 44%|4| 132/301 [90:19:08<115:38:15, 2463.29s/it] 44%|4| 133/301 [91:00:18<115:03:00, 2465.36s/it] 45%|4| 134/301 [91:41:28<114:25:30, 2466.65s/it] 45%|4| 135/301 [92:22:33<113:43:00, 2466.15s/it] 45%|4| 136/301 [93:03:38<113:01:42, 2466.08s/it] 46%|4| 137/301 [93:44:44<112:20:25, 2466.01s/it] 46%|4| 138/301 [94:25:46<111:35:51, 2464.73s/it] 46%|4| 139/301 [95:06:51<110:55:08, 2464.87s/it] 47%|4| 140/301 [95:47:54<110:12:14, 2464.19s/it]